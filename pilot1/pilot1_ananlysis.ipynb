{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text competitive rating to numerical \n",
    "competitive_mapping = {\n",
    "'Extremely uncompetitive': 1,\n",
    "'Uncompetitive': 2,\n",
    "'Somewhat uncompetitive': 3, \n",
    "'Neutral (neither competitive nor uncompetitive)':4,\n",
    "'Somewhat competitive': 5,\n",
    "'Competitive': 6,\n",
    "'Extremely competitive': 7\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth_gender = {\n",
    "'letter1': 'Female',\n",
    "'letter2': 'Female',\n",
    "'letter3': 'Male',\n",
    "'letter4': 'Male'\n",
    "}\n",
    "\n",
    "ground_truth_writer_gender = {\n",
    "'letter1': 'Male',\n",
    "'letter2': 'Male',\n",
    "'letter3': 'Male',\n",
    "'letter4': 'Male'\n",
    "}\n",
    "\n",
    "ground_truth_strength = {\n",
    "'letter1': 'Strong',\n",
    "'letter2': 'Weak',\n",
    "'letter3': 'Strong',\n",
    "'letter4': 'Weak'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('Responses/letter1_female_strong.xlsx')  \n",
    "df2 = pd.read_excel('Responses/letter2_female_weak.xlsx') \n",
    "df3 = pd.read_excel('Responses/letter3_male_strong.xlsx') \n",
    "df4 = pd.read_excel('Responses/letter4_male_weak.xlsx') \n",
    "\n",
    "df1['competitive_score'] = df1['competitiveness'].apply(lambda x: competitive_mapping[x])\n",
    "df2['competitive_score'] = df2['competitiveness'].apply(lambda x: competitive_mapping[x])\n",
    "df3['competitive_score'] = df3['competitiveness'].apply(lambda x: competitive_mapping[x])\n",
    "df4['competitive_score'] = df4['competitiveness'].apply(lambda x: competitive_mapping[x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Gender Question Analysis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove invalid responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove responses where participants simply guessed the answer\n",
    "invalid_index1 = [4,5,9]\n",
    "df1_clean = df1.drop(invalid_index1)\n",
    "\n",
    "invalid_index2 = [1, 5]\n",
    "df2_clean = df2.drop(invalid_index2)\n",
    "\n",
    "invalid_index3 = [2, 8, 12]\n",
    "df3_clean = df3.drop(invalid_index3)\n",
    "\n",
    "invalid_index4 = [1, 2, 3, 4, 5, 9, 10, 11, 12]\n",
    "df4_clean = df4.drop(invalid_index4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of candidate gender question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(df, column, ground_truth):\n",
    "    ans = df[column].values.tolist()\n",
    "    correct = 0\n",
    "    for val in ans:\n",
    "        if val == ground_truth:\n",
    "            correct += 1\n",
    "    # return correct, len(ans) - correct, correct / len(ans)\n",
    "    return correct / len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_accuracy(df1_clean, 'candidate_gender', groud_truth_gender['letter1']))\n",
    "print(get_accuracy(df2_clean, 'candidate_gender', groud_truth_gender['letter2']))\n",
    "print(get_accuracy(df3_clean, 'candidate_gender', groud_truth_gender['letter3']))\n",
    "print(get_accuracy(df4_clean, 'candidate_gender', groud_truth_gender['letter4']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidate gender question confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([df1_clean['candidate_gender_confidence'].describe()['mean'],\n",
    "       df2_clean['candidate_gender_confidence'].describe()['mean'],\n",
    "        df3_clean['candidate_gender_confidence'].describe()['mean'],\n",
    "       df4_clean['candidate_gender_confidence'].describe()['mean']]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of letter writer gender question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_accuracy(df1_clean, 'writer_gender', ground_truth_writer_gender['letter1']))\n",
    "print(get_accuracy(df2_clean, 'writer_gender', ground_truth_writer_gender['letter2']))\n",
    "print(get_accuracy(df3_clean, 'writer_gender', ground_truth_writer_gender['letter3']))\n",
    "print(get_accuracy(df4_clean, 'writer_gender', ground_truth_writer_gender['letter4']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competitiveness Ratings Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['competitive_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['competitive_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['competitive_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[['competitive_score']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified by letter strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = pd.concat([df1,df2])\n",
    "df_male = pd.concat([df3,df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stastical test\n",
    "print(stats.ttest_ind(df_female['competitive_score'].values.tolist(),df_male['competitive_score'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female[['competitive_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male[['competitive_score']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified by letter strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weak = pd.concat([df2,df4])\n",
    "df_strong = pd.concat([df1,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stastical test\n",
    "print(stats.ttest_ind(df_weak['competitive_score'].values.tolist(),df_strong['competitive_score'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strong[['competitive_score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weak[['competitive_score']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified by perceived gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter 1\n",
    "df1_female = df1_clean.loc[df1_clean['candidate_gender'] == 'Female']\n",
    "df1_male = df1_clean.loc[df1_clean['candidate_gender'] == 'Male']\n",
    "\n",
    "df1_female.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_male.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter 2\n",
    "df2_female = df2_clean.loc[df2_clean['candidate_gender'] == 'Female']\n",
    "df2_male = df2_clean.loc[df2_clean['candidate_gender'] == 'Male']\n",
    "\n",
    "df2_female.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_male.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter 3\n",
    "df3_female = df3_clean.loc[df3_clean['candidate_gender'] == 'Female']\n",
    "df3_male = df3_clean.loc[df3_clean['candidate_gender'] == 'Male']\n",
    "\n",
    "df3_female.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_male.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter 4\n",
    "df4_female = df4_clean.loc[df4_clean['candidate_gender'] == 'Female']\n",
    "df4_male = df4_clean.loc[df4_clean['candidate_gender'] == 'Male']\n",
    "\n",
    "df4_female.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_male.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
